# Resource Repository for Deep Learning Model Inversion Attacks and Defenses
This is a comprehensive resource repository for deep learning model inversion attacks and defenses research.


## Taxonomy of Model Inversion Attacks

|         Method         |                                Paper                                 |                                                    Source                                                     |   Code   |
|:----------------------:|:-------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------:|:--------:|
|   DLG  | Deep Leakage from Gradients | [NeurIPS'2019](https://proceedings.neurips.cc/paper/2019/hash/60a6c4002cc7b29142def8871531281a-Abstract.html) |     -     |
|      iDLG    |                              iDLG: Improved Deep Leakage from Gradients                           |                                              [arXiv](https://arxiv.org/abs/2001.02610)                                                   |     -     |
|  AGIC  |  AGIC: Approximate Gradient Inversion Attack on Federated Learning  |  [SRDS'2022](https://ieeexplore.ieee.org/abstract/document/9996844?casa_token=HW2g88ZKvyYAAAAA:ynaPpf6qzZY8ptc31j9lSHEIkP8B2skFskNLT3-xUjbdIK1mqtRGAT_ErtT1_beOGl0upNGNCSD1)  |  -  |
|  RGCIR  |  An effective and practical gradient inversion attack  |  [IJIS'2022](https://onlinelibrary.wiley.com/doi/10.1002/int.22997)  |  -  |
|  LOMMA  |  Re-Thinking Model Inversion Attacks Against Deep Neural Networks  |  [CVPR'2023](https://openaccess.thecvf.com/content/CVPR2023/html/Nguyen_Re-Thinking_Model_Inversion_Attacks_Against_Deep_Neural_Networks_CVPR_2023_paper.html)  |  [ https://ngoc-nguyen-0.github.io/re-thinking_model_inversion_attacks/]( https://ngoc-nguyen-0.github.io/re-thinking_model_inversion_attacks/)  |
|  EGIA  |  Egia: An external gradient inversion attack in federated learning  |  [TIFS'2023](https://ieeexplore.ieee.org/abstract/document/10209197?casa_token=8Z3tPnQDgvsAAAAA:sla4sO1caXCPVZrPFa62KkpjqDYcpuUAS2Y8UloY8lj0gJn3dZAqFbwcQwFdJICLoKvnCmmHdbOc)  |  [https://github.com/RuslandGadget/FCN-Inv](https://github.com/RuslandGadget/FCN-Inv)  |
|  SGI  |  High-Fidelity Gradient Inversion in Distributed Learning  |  [AAAI'20224](https://ojs.aaai.org/index.php/AAAI/article/view/29975)  |  [https://github.com/MiLab-HITSZ/2023YeHFGradInv](https://github.com/MiLab-HITSZ/2023YeHFGradInv)  |
|  GGI  |  GGI: Generative Gradient Inversion Attack in Federated Learning  |  [DOCS'2024](https://ieeexplore.ieee.org/document/10704504)  |  -  |
ï½œ  GI-NAS  |  GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search  |  [arXiv](https://arxiv.org/abs/2405.20725)  |  -  |





## Defenses Against Model Inversion Attacks

| Method | Paper  | Source | Code | 
|---|---|---|---|
| Row 1, Cell 1 | Row 1, Cell 2 | Row 1, Cell 3 |---|
| Row 2, Cell 1 | Row 2, Cell 2 | Row 2, Cell 3 |---|

## Evaluation Metrics in MI Attacks and Defenses


## Datasets for MI Attack Research
